# Flink 解释器

原文链接 : [http://zeppelin.apache.org/docs/0.7.2/interpreter/flink.html](http://zeppelin.apache.org/docs/0.7.2/interpreter/flink.html)

译文链接 : [http://www.apache.wiki/pages/viewpage.action?pageId=10030795](http://www.apache.wiki/pages/viewpage.action?pageId=10030795)

贡献者 : [片刻](/display/~jiangzhonglian) [ApacheCN](/display/~apachecn) [Apache中文网](/display/~apachechina)

## 概述

[Apache Flink](https://flink.apache.org/)是分布式流和批处理数据处理的开源平台。Flink的核心是流数据流引擎，为数据流上的分布式计算提供数据分发，通信和容错。Flink还在流式引擎之上构建批处理，覆盖本机迭代支持，托管内存和程序优化。

## 如何启动本地Flink群集，来测试解释器

Zeppelin配有预配置的flink-local解释器，它在您的机器上以本地模式启动Flink，因此您不需要安装任何东西。

## 如何配置解释器来指向Flink集群

在“解释器”菜单中，您必须创建一个新的Flink解释器并提供下一个属性：

| 属性 | 值 | 描述 |
| --- | --- | --- |
| host | local | 运行JobManager的主机名。'local'在本地模式下运行flink（默认） |
| port | 6123 | 运行JobManager的端口 |

有关Flink配置的更多信息，可以在[这里](https://ci.apache.org/projects/flink/flink-docs-release-1.0/setup/config.html)找到。

## 如何测试它的工作

您可以在Zeppelin Tutorial文件夹中找到Flink使用的示例，或者尝试以下字数计数示例，方法是使用Till Rohrmann演示文稿中的[Zeppelin笔记本](https://www.zeppelinhub.com/viewer/notebooks/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL05GTGFicy96ZXBwZWxpbi1ub3RlYm9va3MvbWFzdGVyL25vdGVib29rcy8yQVFFREs1UEMvbm90ZS5qc29u) 与Apache Flink for Apache Flink Meetup进行[交互式数据分析](http://www.slideshare.net/tillrohrmann/data-analysis-49806564)。

```
%sh 
rm 10.txt.utf-8 
wget http://www.gutenberg.org/ebooks/10.txt.utf-8 

%flink
case class WordCount(word: String, frequency: Int)
val bible:DataSet[String] = benv.readTextFile("10.txt.utf-8")
val partialCounts: DataSet[WordCount] = bible.flatMap{
    line =>
        """\b\w+\b""".r.findAllIn(line).map(word => WordCount(word, 1))
// line.split(" ").map(word => WordCount(word, 1))
}
val wordCounts = partialCounts.groupBy("word").reduce{
    (left, right) => WordCount(left.word, left.frequency + right.frequency)
}
val result10 = wordCounts.first(10).collect()
```
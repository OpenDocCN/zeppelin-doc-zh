# Livy 解释器

原文链接 : [http://zeppelin.apache.org/docs/0.7.2/interpreter/livy.html](http://zeppelin.apache.org/docs/0.7.2/interpreter/livy.html)

译文链接 : [http://www.apache.wiki/pages/viewpage.action?pageId=10030858](http://www.apache.wiki/pages/viewpage.action?pageId=10030858)

贡献者 : [片刻](/display/~jiangzhonglian) [ApacheCN](/display/~apachecn) [Apache中文网](/display/~apachechina)

## 概述

[Livy](http://livy.io/)是一个开源REST接口，用于与任何地方的Spark进行交互。它支持在本地运行或在YARN中运行的Spark上下文中执行代码或程序片段。

*   交互式Scala，Python和R shell
*   在Scala，Java，Python中批量提交
*   多用户可以共享相同的服务器（模拟支持）
*   可以使用REST从任何地方提交作业
*   不需要对程序进行任何代码更改

### 要求

Livy解释器的附加要求是：

*   Spark 1.3或以上。
*   Livy服务器。

## 组态 

我们为火花添加了一些常见的配置，您可以设置所需的任何配置。您可以在[这里](http://spark.apache.org/docs/latest/configuration.html#available-properties)找到所有的Spark配置。而不是用`spark.`它开始的财产应该被替换`livy.spark.`。例如：`spark.driver.memory`到`livy.spark.driver.memory`

| 属性 | 默认 | 描述 |
| --- | --- | --- |
| zeppelin.livy.url | [http://localhost:8998](http://localhost:8998) | livy服务器正在运行的URL |
| zeppelin.livy.spark.maxResult | 1000 | 要显示的Spark SQL结果的最大数量。 |
| zeppelin.livy.session.create_timeout | 120 | 会话创建超时秒数 |
| zeppelin.livy.displayAppInfo | false | 是否显示应用信息 |
| zeppelin.livy.pull_status.interval.millis | 1000 | 检查段执行状态的间隔 |
| livy.spark.driver.cores |   | 驱动核心 ex）1，2。 |
| livy.spark.driver.memory |   | 驱动内存 ex）512m，32g。 |
| livy.spark.executor.instances |   | 执行器实例。ex）1，4。 |
| livy.spark.executor.cores |   | 每个执行者的数字核心。ex）1，4。 |
| livy.spark.executor.memory |   | 每个worker实例的执行程序内存。ex）512m，32g。 |
| livy.spark.dynamicAllocation.enabled |   | 使用动态资源分配。ex）是的，假的。 |
| livy.spark.dynamicAllocation.cachedExecutorIdleTimeout |   | 删除已缓存数据块的执行器。 |
| livy.spark.dynamicAllocation.minExecutors |   | 执行人数下限。 |
| livy.spark.dynamicAllocation.initialExecutors |   | 运行的初始执行者数。 |
| livy.spark.dynamicAllocation.maxExecutors |   | 上限为执行人数。 |
| livy.spark.jars.packages |   | 向livy解释器添加额外的库 |

**我们删除zeppelin-0.7中的livy.spark.master。因为我们建议用户在zeppelin-0.7中使用livy 0.3。而livy 0.3不允许指定livy.spark.master，它强制执行纱线集群模式。**

## 添加外部库

您可以通过set `livy.spark.jars.packages`属性将动态库加载到livy解释器，以逗号分隔的jars的maven坐标列表来包含在驱动程序和执行器类路径上。坐标的格式应为groupId：artifactId：version。

案例

| 属性 | 案例 | 描述 |
| --- | --- | --- |
| livy.spark.jars.packages | io.spray:spray-json_2.10:1.3.1 | 向livy解释器添加额外的库 |

## 如何使用

基本上可以使用

**spark**

```
%livy.spark 
sc.version  
```

**pyspark**

```
%livy.pyspark 
print "1"  
```

**sparkR**

```
%livy.sparkr 
hello <- function( name ) { 
    sprintf( "Hello, %s", name ); 
} 

hello("livy") 
```

## 模拟

当Zeppelin服务器运行时启用身份验证，则此解释器利用Livy的用户模拟功能，即为创建和运行会话（“proxyUser”：“$ {loggedInUser}”）发送额外的参数。这在多用户共享一个Notebook服务器时特别有用。

## 应用Zeppelin动态表单

您可以利用[Zeppelin 动态表单](http://www.apache.wiki/pages/viewpage.action?pageId=10030585)。您可以同时使用`text input`和`select form`参数化功能。

```
%livy.pyspark 
print "${group_by=product_id,product_id|product_name|customer_id|store_id}" 
```

## 常问问题

Livy调试：如果您在错误控制台中看到这些错误

> 连接到 livyhost:8998 [livyhost/127.0.0.1, livyhost/0:0:0:0:0:0:0:1] 失败：连接拒绝

看起来像livy服务器还没有或配置是错误的

> 异常：会话未找到，Livy服务器将重新启动或丢失会话。

会话将超时，您可能需要重新启动解释器。

> 会话配置中列出黑名单的配置值：spark.master

 `conf/spark-blacklist.conf`在livy服务器中编辑文件并注释掉`#spark.master`。

如果您选择在 [https://github.com/cloudera/hue](https://github.com/cloudera/hue) 中的`apps/spark/java`livy目录中工作，请在livy服务器中复制`spark-user-configurable-options.template`到`spark-user-configurable-options.conf`文件并注释掉`#spark.master`。